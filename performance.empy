@# -*- html -*-

@{page_id = "performance"}
@{page_title = "Performance"}
@empy.include("header.empy")

<p>The performance of ccache depends on a lot of factors, which makes it quite
hard to predict the improvement for a given use case. This page contains some
different performance measurements that try to give an idea about the potential
speedup.</p>

<p>It should also be noted that if the expected hit rate is low, there may be a
net performance loss when using ccache because of the overhead of cache misses
(typically 5%-20%). Also, if the build machine is short on memory compared to
the amount of memory used by the build tools (compiler, linker, etc), usage of
ccache could decrease performance due the fact that ccache's cached files may
flush other files from the OS's disk cache.
See <a href="http://www.mail-archive.com/ccache@@lists.samba.org/msg00576.html">this
mailing list post</a> by Christopher Tate for a good write-up on this issue. So
to sum it up: it is probably wise to perform some measurements with and without
ccache for your typical use case before enabling it!</p>

<p>The following measurements were made on a fairly standard Linux-based
desktop system: Intel Core i5-4690K, standard SSD disk, Ubuntu 19.04 with Linux
5.0.0.</p>

<p>&ldquo;ccache 3.7.1 direct&rdquo; in the tables below means running ccache
with direct mode enabled (which is the default) and &ldquo;ccache 3.7.1
prepr.&rdquo; means running ccache with a disabled depend mode, thus falling
back to the preprocessor mode. &ldquo;ccache 3.7.1 depend&rdquo; means running
ccache with the depend mode enabled.</p>

<p>
  All results were gathered by timing 100 individual compilations and picking
  the median result.
</p>


<h2>ccache.c</h2>

<p>Here are the results of building ccache's
own <a href="https://github.com/ccache/ccache/blob/master/ccache.c">ccache.c</a>
with <code>-g -O2 -MD</code> and needed <code>-I</code> flags:</p>

<table class="perf">
<tr>
  <th class="empty"></th>
  <th>Elapsed time</th>
  <th>Percent</th>
  <th>Factor</th>
</tr>
<tr>
  <th>Without ccache</th>
  <td class="num">0.6988 s</td>
  <td class="num">100.00 %</td>
  <td class="num">1.0000 x</td>
</tr>
<tr>
  <th>ccache 3.7.1 prepr., first time</th>
  <td class="num">0.7251 s</td>
  <td class="num">103.7708 %</td>
  <td class="num">0.9637 x</td>
</tr>
<tr>
  <th>ccache 3.7.1 prepr., second time</th>
  <td class="num">0.0247 s</td>
  <td class="num">3.5296 %</td>
  <td class="num">28.3321 x</td>
</tr>
<tr>
  <th>ccache 3.7.1 direct, first time</th>
  <td class="num">0.7268 s</td>
  <td class="num">104.0137 %</td>
  <td class="num">0.9614 x</td>
</tr>
<tr>
  <th>ccache 3.7.1 direct, second time</th>
  <td class="num">0.0048 s</td>
  <td class="num">0.6878 %</td>
  <td class="num">145.3918 x</td>
</tr>
<tr>
  <th>ccache 3.7.1 depend, first time</th>
  <td class="num">0.7102 s</td>
  <td class="num">101.6393 %</td>
  <td class="num">0.9839 x</td>
</tr>
<tr>
  <th>ccache 3.7.1 depend, second time</th>
  <td class="num">0.0051 s</td>
  <td class="num">0.7256 %</td>
  <td class="num">137.8137 x</td>
</tr>
</table>

<p>As can be seen above, cache hits in the direct mode are about 5 times faster
than in the preprocessor mode. The speedup compared to compiling without ccache
is very large since the compilation costs a relatively large amount of CPU
time. The overhead of cache misses can also be seen, but it's smaller for the
depend mode.</p>

<h2>c++_includes.cc</h2>

<p>This is a test that aims to measure preprocessor-intensive compilation.
Here, <a href="c++_includes.cc">c++_includes.cc</a> (a file including nine
common include files from the C++ standard library) was compiled without any
special flags other than <code>-MD</code> to enable usage of the depend
mode:</p>

<table class="perf">
<tr>
  <th class="empty"></th>
  <th>Elapsed time</th>
  <th>Percent</th>
  <th>Factor</th>
</tr>
<tr>
  <th>Without ccache</th>
  <td class="num">0.2421 s</td>
  <td class="num">100.00 %</td>
  <td class="num">1.0000 x</td>
</tr>
<tr>
  <th>ccache 3.7.1 prepr., first time</th>
  <td class="num">0.2892 s</td>
  <td class="num">119.4580 %</td>
  <td class="num">0.8371 x</td>
</tr>
<tr>
  <th>ccache 3.7.1 prepr., second time</th>
  <td class="num">0.0496 s</td>
  <td class="num">19.6508 %</td>
  <td class="num">5.0888 x</td>
</tr>
<tr>
  <th>ccache 3.7.1 direct, first time</th>
  <td class="num">0.2919 s</td>
  <td class="num">120.5838 %</td>
  <td class="num">0.8293 x</td>
</tr>
<tr>
  <th>ccache 3.7.1 direct, second time</th>
  <td class="num">0.0083 s</td>
  <td class="num">3.3464 %</td>
  <td class="num">29.1004 x</td>
</tr>
<tr>
  <th>ccache 3.7.1 depend, first time</th>
  <td class="num">0.2495 s</td>
  <td class="num">103.0848 %</td>
  <td class="num">0.9701 x</td>
</tr>
<tr>
  <th>ccache 3.7.1 depend, second time</th>
  <td class="num">0.0083 s</td>
  <td class="num">3.4106 %</td>
  <td class="num">29.3206 x</td>
</tr>
</table>

<p>The difference between direct and preprocessor mode hits is about a factor 6
&mdash; slightly higher than for the ccache.c test because the preprocessor
overhead is higher. The depend mode really shines here since running the
preprocessor on cache misses in the depend mode is costly.</p>

<h2>Samba 3.5.3</h2>

<p>
  (<b>NOTE:</b> This section was written in 2010 when ccache 3.0 was released
  so it's a bit dated.)
</p>

<p>Here is a perhaps more realistic use case. First,
the <a href="https://www.samba.org">Samba</a> 3.5.3 source code was
unpacked, <code>./configure</code> was run and then <code>make</code>
(without <code>-j</code>) was run and timed. All tests were run eight times and
only the best results were kept. Note that the figures also include linking and
other things that aren't affected by ccache.</p>

<h3>Warm disk cache</h3>

<table class="perf">
<tr>
  <th class="empty"></th>
  <th>Elapsed time</th>
  <th>Percent</th>
  <th>Factor</th>
</tr>
<tr>
  <th>Without ccache</th>
  <td class="num">316.23 s</td>
  <td class="num">100.00 %</td>
  <td class="num">1.0000 x</td>
</tr>
<tr>
  <th>ccache 3.0 prepr., first time</th>
  <td class="num">360.62 s</td>
  <td class="num">114.04 %</td>
  <td class="num">0.8769 x</td>
</tr>
<tr>
  <th>ccache 3.0 prepr., second time</th>
  <td class="num">161.44 s</td>
  <td class="num">51.05 %</td>
  <td class="num">1.9588 x</td>
</tr>
<tr>
  <th>ccache 3.0 direct, first time</th>
  <td class="num">375.16 s</td>
  <td class="num">118.64 %</td>
  <td class="num">0.8429 x</td>
</tr>
<tr>
  <th>ccache 3.0 direct, second time</th>
  <td class="num">32.09 s</td>
  <td class="num">10.15 %</td>
  <td class="num">9.8545 x</td>
</tr>
</table>

<p>The cost of cache misses is relatively high: 14% for the preprocessor mode
and 19% for the direct mode. The direct mode has higher overhead than the
preprocessor mode for cache misses, but is much faster for cache hits. In fact,
the speedup is in this case so high that it may become interesting to optimize
how the Makefile is written. The rule for compiling a C file in Samba 3.5.3
looks like this:</p>

<pre>
.c.o:
	@@if (: &gt;&gt; $@@ || : &gt; $@@) &gt;/dev/null 2&gt;&amp;1; then rm -f $@@; else \
	 dir=`echo $@@ | sed 's,/[^/]*$$,,;s,^$$,.,'` $(MAKEDIR); fi
	@@if test -n "$(CC_CHECKER)"; then \
	  echo "Checking  $*.c with '$(CC_CHECKER)'";\
	  $(CHECK_CC); \
	 fi
	@@echo Compiling $*.c
	@@$(COMPILE) &amp;&amp; exit 0;\
		echo "The following command failed:" 1&gt;&amp;2;\
		echo "$(subst ",\",$(COMPILE_CC))" 1&gt;&amp;2;\
		$(COMPILE_CC) &gt;/dev/null 2&gt;&amp;1
</pre>

By rewriting this to

<pre>
.c.o:
	@@echo Compiling $*.c
	@@$(COMPILE)
</pre>

<p>the build time goes down from 32 seconds to about 23 seconds!</p>

<h3>Cold disk cache</h3>

<p>To measure the speed when the disk cache is cold, the disk cache was dropped
with <code>sync; echo 3 >/proc/sys/vm/drop_caches</code> before
running <code>make</code>.</p>

<table class="perf">
<tr>
  <th class="empty"></th>
  <th>Elapsed time</th>
  <th>Percent</th>
  <th>Factor</th>
</tr>
<tr>
  <th>Without ccache</th>
  <td class="num">324.08 s</td>
  <td class="num">100.00 %</td>
  <td class="num">1.0000 x</td>
</tr>
<tr>
  <th>ccache 3.0 prepr., first time</th>
  <td class="num">367.82 s</td>
  <td class="num">116.31 %</td>
  <td class="num">0.8597 x</td>
</tr>
<tr>
  <th>ccache 3.0 prepr., second time</th>
  <td class="num">172.34 s</td>
  <td class="num">54.50 %</td>
  <td class="num">1.8349 x</td>
</tr>
<tr>
  <th>ccache 3.0 direct, first time</th>
  <td class="num">382.24 s</td>
  <td class="num">120.87 %</td>
  <td class="num">0.8273 x</td>
</tr>
<tr>
  <th>ccache 3.0 direct, second time</th>
  <td class="num">44.59 s</td>
  <td class="num">14.10 %</td>
  <td class="num">7.0919 x</td>
</tr>
</table>

<p>A cold disk cache makes the performance gain on hits slightly lower because
of the extra disk cache misses for files in the ccache directory.</p>

@empy.include("footer.empy")
